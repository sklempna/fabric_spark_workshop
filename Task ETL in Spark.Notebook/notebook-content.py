# Fabric notebook source


# MARKDOWN ********************

# # Task: ETL in Spark
# 
# This notebook is for you to get experience using Spark for ETL. 
# 
# **Task 1:**
# - Create a duplicate of this notebook and save it to your personal folder
# - Connect the notebook to your personal Lakehouse inside your folder
# - Create a shortcut to the Workshop_LH
# - Read the contents of `OnlineSales.csv` into a Pyspark dataframe and display it

# CELL ********************

# Execute code here


# MARKDOWN ********************

# **Task 2:**
# - From how many distinct years are there sales records? What is the earliest/latest recorded sales date

# CELL ********************

# Execute code here

# MARKDOWN ********************

# **Task 3:**
# - What which was the year with the most and the fewest Sales?

# CELL ********************

# Execute code here

# MARKDOWN ********************

# **Task 4:**
# - How many unique customers were there in the year with the most sales?

# CELL ********************

# Execute code here

# MARKDOWN ********************

# **Task 5:**
# - Are there customers that purchased something in every recorded year?

# CELL ********************

# Execute code here

# MARKDOWN ********************

# **Task 6:**
# - Create a table (inside your personal Lakehouse) that contains your favourite per-year-metrics 

# CELL ********************

# Execute code here
